{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2475b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import nibabel as nib # to load and save neuroimaging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c83f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageReader:\n",
    "    \"\"\"\n",
    "    ImageReader class. The load_patient_scan method of the ImageReader class reads in all the scan types \n",
    "    specified in scan_types and concatenates them along the channel dimension before returning them.\n",
    "    \n",
    "    Note:\n",
    "        A common approach is to train a model using all the modalities, \n",
    "        concatenating the different modalities along the channel dimension of the input tensor. \n",
    "        This allows the model to take advantage of the information provided by each modality.\n",
    "    \"\"\"\n",
    "    def __init__(self, root:str, img_size:int=256, normalize:bool=False, single_class:bool=False, scan_types:list=['flair', 't1', 't1ce', 't2']):\n",
    "        self.scan_types = scan_types\n",
    "        self.pad_size = 256 if img_size > 256 else 224\n",
    "        self.resize = A.Compose(\n",
    "            [\n",
    "                A.PadIfNeeded(min_height=self.pad_size, min_width=self.pad_size, value=0),\n",
    "                A.Resize(img_size, img_size)\n",
    "            ]\n",
    "        )\n",
    "        self.normalize=normalize\n",
    "        self.single_class=single_class\n",
    "        self.root=root\n",
    "        \n",
    "    def read_file(self, path:str) -> dict:\n",
    "        raw_image = nib.load(path).get_fdata()\n",
    "        raw_mask = nib.load(path.replace(path.split('_')[-1], 'seg.nii.gz')).get_fdata()\n",
    "        processed_frames, processed_masks = [], []\n",
    "        for frame_idx in range(raw_image.shape[2]):\n",
    "            frame = raw_image[:, :, frame_idx]\n",
    "            mask = raw_mask[:, :, frame_idx]\n",
    "            if self.normalize:\n",
    "                if frame.max() > 0:\n",
    "                    frame = frame/frame.max()\n",
    "                frame = frame.astype(np.float32)\n",
    "            else:\n",
    "                frame = frame.astype(np.uint8)\n",
    "            resized = self.resize(image=frame, mask=mask)\n",
    "            processed_frames.append(resized['image'])\n",
    "            processed_masks.append(1*(resized['mask'] > 0) if self.single_class else resized['mask'])\n",
    "        return {\n",
    "            'scan': np.stack(processed_frames, 0),\n",
    "            'segmentation': np.stack(processed_masks, 0),\n",
    "            'orig_shape': raw_image.shape\n",
    "        }\n",
    "    \n",
    "    def load_patient_scan(self, idx:int, segmentation:np.ndarray) -> dict:\n",
    "        patient_id = str(idx).zfill(5)\n",
    "        scan_list = []\n",
    "        for scan_type in self.scan_types:\n",
    "            scan_filename = f'{self.root}/BraTS2021_{patient_id}/BraTS2021_{patient_id}_{scan_type}.nii.gz'\n",
    "            scan_list.append(nib.load(scan_filename).get_fdata())\n",
    "        return {\n",
    "            'scan': np.concatenate(scan_list, axis=0),\n",
    "            'segmentation': segmentation,\n",
    "            'orig_shape': scan_list[0].shape\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1b8bac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BratsDataLoader(Dataset):\n",
    "    \"\"\"\n",
    "    BratsDataLoader class takes the same arguments as the previous version, \n",
    "    but it also takes an additional argument scan_types, which is passed to the ImageReader class. \n",
    "    The load_patient_scan method of the ImageReader class reads in all the scan types specified in scan_types \n",
    "    and concatenates them along the channel dimension before returning them.\n",
    "    \"\"\"\n",
    "    def __init__(self, root:str, img_size:int=256, normalize:bool=False, single_class:bool=False, scan_types:list=['flair', 't1', 't1gd', 't2']):\n",
    "        self.image_reader = ImageReader(root, img_size, normalize, single_class, scan_types)\n",
    "        self.root = root\n",
    "        self.patient_ids = [d.split(\"_\")[-1] for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.patient_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = self.patient_ids[idx]\n",
    "        scan_filename = f'{self.root}/BraTS2021_{patient_id}/BraTS2021_{patient_id}_seg.nii.gz'\n",
    "        segmentation = nib.load(scan_filename).get_fdata()\n",
    "        patient_data = self.image_reader.load_patient_scan(patient_id, segmentation)\n",
    "        scan = patient_data['scan']\n",
    "        segmentation = patient_data['segmentation']\n",
    "        return {'scan': torch.from_numpy(scan), 'segmentation': torch.from_numpy(segmentation)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37d73cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scan:  torch.Size([16, 960, 240, 155])\n",
      "Shape of segmentation:  torch.Size([16, 240, 240, 155])\n",
      "Data type of scan:  torch.float64\n",
      "Data type of segmentation:  torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Test the dataloader\n",
    "\n",
    "root = \"/home/ardamamur/TUM/ML3D/dataset/\"\n",
    "dataset = root + \"train\"\n",
    "labels = root + \"train_labels.csv\"\n",
    "\n",
    "data_loader = DataLoader(BratsDataLoader(root=dataset, img_size=256, normalize=True, single_class=True, scan_types=['flair', 't1', 't1ce', 't2']),\n",
    "                         batch_size=16, shuffle=True, num_workers=0)\n",
    "\n",
    "# Get a batch of data\n",
    "data = next(iter(data_loader))\n",
    "\n",
    "# Check the shape of the data\n",
    "scan = data['scan']\n",
    "segmentation = data['segmentation']\n",
    "print(\"Shape of scan: \", scan.shape)\n",
    "print(\"Shape of segmentation: \", segmentation.shape)\n",
    "\n",
    "# Check the data type of the data\n",
    "print(\"Data type of scan: \", scan.dtype)\n",
    "print(\"Data type of segmentation: \", segmentation.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d962525f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d00c11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3d_project",
   "language": "python",
   "name": "ml3d_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
